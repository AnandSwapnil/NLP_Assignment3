{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "-4nDPvbHif8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt"
      ],
      "metadata": {
        "id": "9eEbVsy0H99u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664a7028-426b-4924-d6ae-08cad69d1b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-15 17:15:34--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375849 (367K) [text/plain]\n",
            "Saving to: ‘train_data.txt’\n",
            "\n",
            "\rtrain_data.txt        0%[                    ]       0  --.-KB/s               \rtrain_data.txt      100%[===================>] 367.04K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-11-15 17:15:34 (39.1 MB/s) - ‘train_data.txt’ saved [375849/375849]\n",
            "\n",
            "--2024-11-15 17:15:34--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77062 (75K) [text/plain]\n",
            "Saving to: ‘test_data.txt’\n",
            "\n",
            "test_data.txt       100%[===================>]  75.26K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-11-15 17:15:34 (42.3 MB/s) - ‘test_data.txt’ saved [77062/77062]\n",
            "\n",
            "--2024-11-15 17:15:35--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77120 (75K) [text/plain]\n",
            "Saving to: ‘noisy_test_data.txt’\n",
            "\n",
            "noisy_test_data.txt 100%[===================>]  75.31K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-11-15 17:15:35 (27.9 MB/s) - ‘noisy_test_data.txt’ saved [77120/77120]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Read data from files\n",
        "def read_data(filename):\n",
        "    sentences = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            sentences.append([tuple(word.split('/')) for word in line.strip().split()])\n",
        "    return sentences\n",
        "\n",
        "# Load training, test, and noisy test data\n",
        "train_data = read_data('/content/train_data.txt')\n",
        "test_data = read_data('/content/test_data.txt')\n",
        "noisy_test_data = read_data('/content/noisy_test_data.txt')\n"
      ],
      "metadata": {
        "id": "1Sq1eIU_0Jv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Derive hidden and observable states from training data and building Hidden Markovnikov Model\n",
        "def build_hmm(train_data):\n",
        "    transition_probs = defaultdict(lambda: defaultdict(int))\n",
        "    emission_probs = defaultdict(lambda: defaultdict(int))\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    for sentence in train_data:\n",
        "        prev_tag = '<START>'\n",
        "        for item in sentence:\n",
        "            if len(item) != 2:\n",
        "                continue  # Skip elements that don't have exactly (word, tag) format\n",
        "\n",
        "            word, tag = item\n",
        "            transition_probs[prev_tag][tag] += 1\n",
        "            emission_probs[tag][word] += 1\n",
        "            tag_counts[tag] += 1\n",
        "            prev_tag = tag\n",
        "        transition_probs[prev_tag]['<END>'] += 1\n",
        "\n",
        "    # Normalize probabilities\n",
        "    transition_probs = {\n",
        "        k: {k2: v2 / sum(v.values()) for k2, v2 in v.items()}\n",
        "        for k, v in transition_probs.items()\n",
        "    }\n",
        "    emission_probs = {\n",
        "        k: {k2: v2 / tag_counts[k] for k2, v2 in v.items()}\n",
        "        for k, v in emission_probs.items()\n",
        "    }\n",
        "\n",
        "    return transition_probs, emission_probs, list(tag_counts.keys())\n",
        "\n",
        "# Build HMM\n",
        "transition_probs, emission_probs, tags = build_hmm(train_data)\n",
        "\n",
        "\n",
        "# Viterbi Algorithm\n",
        "def viterbi(sentence, tags, transition_probs, emission_probs):\n",
        "    n = len(sentence)\n",
        "    m = len(tags)\n",
        "    dp = np.zeros((n, m))\n",
        "    backpointer = np.zeros((n, m), dtype=int)\n",
        "\n",
        "    # Initialize\n",
        "    for j, tag in enumerate(tags):\n",
        "        dp[0, j] = transition_probs['<START>'].get(tag, 0) * emission_probs[tag].get(sentence[0], 1e-6)\n",
        "\n",
        "    # Fill DP Table\n",
        "    for i in range(1, n):\n",
        "        for j, tag in enumerate(tags):\n",
        "            max_prob = -1\n",
        "            best_prev_tag = -1\n",
        "            for k, prev_tag in enumerate(tags):\n",
        "                prob = dp[i-1, k] * transition_probs[prev_tag].get(tag, 1e-6) * emission_probs[tag].get(sentence[i], 1e-6)\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_prev_tag = k\n",
        "            dp[i, j] = max_prob\n",
        "            backpointer[i, j] = best_prev_tag\n",
        "\n",
        "    # Termination\n",
        "    best_path = []\n",
        "    max_final_prob = -1\n",
        "    best_final_tag = -1\n",
        "    for j, tag in enumerate(tags):\n",
        "        prob = dp[-1, j] * transition_probs[tag].get('<END>', 1e-6)\n",
        "        if prob > max_final_prob:\n",
        "            max_final_prob = prob\n",
        "            best_final_tag = j\n",
        "\n",
        "    # Backtrace\n",
        "    current_tag = best_final_tag\n",
        "    for i in range(n-1, -1, -1):\n",
        "        best_path.insert(0, tags[current_tag])\n",
        "        current_tag = backpointer[i, current_tag]\n",
        "\n",
        "    return best_path\n",
        "\n",
        "\n",
        "# Handle Noisy Data\n",
        "# Adjust emission probabilities for unknown words\n",
        "def handle_noise(emission_probs, unseen_penalty=1e-6):\n",
        "    for tag in emission_probs.keys():\n",
        "        emission_probs[tag]['<UNK>'] = unseen_penalty\n",
        "    return emission_probs\n",
        "\n",
        "# Adjust emission probabilities to handle noise\n",
        "emission_probs_noisy = handle_noise(emission_probs)\n",
        "\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate(test_data, tags, transition_probs, emission_probs):\n",
        "    correct, total = 0, 0\n",
        "    for sentence in test_data:\n",
        "        # Separate words and actual tags from the sentence tuple\n",
        "        words, true_tags = zip(*sentence)\n",
        "\n",
        "        # Predict tags using Viterbi\n",
        "        predicted_tags = viterbi(words, tags, transition_probs, emission_probs)\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
        "        total += len(true_tags)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate baseline Viterbi on the test data\n",
        "baseline_accuracy = evaluate(test_data, tags, transition_probs, emission_probs)\n",
        "\n",
        "# Evaluate noise-handled Viterbi on the noisy test data\n",
        "noise_handled_accuracy = evaluate(noisy_test_data, tags, transition_probs, emission_probs_noisy)\n",
        "\n",
        "# Output Results\n",
        "print(f\"Baseline Viterbi Accuracy: {baseline_accuracy * 100:.2f}%\")\n",
        "print(f\"Noise-handled Viterbi Accuracy: {noise_handled_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHKdrq4g0J5D",
        "outputId": "9d7f209a-cbec-424e-e1f9-797823a13791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Viterbi Accuracy: 90.18%\n",
            "Noise-handled Viterbi Accuracy: 81.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "egzJoO7WhAf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7nH7DessOTSd"
      }
    }
  ]
}